{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Install Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./venv/lib/python3.12/site-packages (2.18.0)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./venv/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: rich in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in ./venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading scipy-1.15.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.15.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- -----------\n",
      "absl-py                 2.1.0\n",
      "asttokens               2.4.1\n",
      "astunparse              1.6.3\n",
      "certifi                 2024.8.30\n",
      "charset-normalizer      3.4.0\n",
      "comm                    0.2.2\n",
      "contourpy               1.3.1\n",
      "cycler                  0.12.1\n",
      "debugpy                 1.8.9\n",
      "decorator               5.1.1\n",
      "executing               2.1.0\n",
      "flatbuffers             24.3.25\n",
      "fonttools               4.55.0\n",
      "gast                    0.6.0\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.68.0\n",
      "h5py                    3.12.1\n",
      "idna                    3.10\n",
      "ipykernel               6.29.5\n",
      "ipython                 8.29.0\n",
      "jedi                    0.19.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.7.2\n",
      "keras                   3.6.0\n",
      "kiwisolver              1.4.7\n",
      "libclang                18.1.1\n",
      "Markdown                3.7\n",
      "markdown-it-py          3.0.0\n",
      "MarkupSafe              3.0.2\n",
      "matplotlib              3.9.2\n",
      "matplotlib-inline       0.1.7\n",
      "mdurl                   0.1.2\n",
      "ml-dtypes               0.4.1\n",
      "namex                   0.0.8\n",
      "nest-asyncio            1.6.0\n",
      "numpy                   2.0.2\n",
      "opencv-python           4.10.0.84\n",
      "opt_einsum              3.4.0\n",
      "optree                  0.13.1\n",
      "packaging               24.2\n",
      "parso                   0.8.4\n",
      "pexpect                 4.9.0\n",
      "pillow                  11.0.0\n",
      "pip                     24.2\n",
      "platformdirs            4.3.6\n",
      "prompt_toolkit          3.0.48\n",
      "protobuf                5.28.3\n",
      "psutil                  6.1.0\n",
      "ptyprocess              0.7.0\n",
      "pure_eval               0.2.3\n",
      "Pygments                2.18.0\n",
      "pyparsing               3.2.0\n",
      "python-dateutil         2.9.0.post0\n",
      "pyzmq                   26.2.0\n",
      "requests                2.32.3\n",
      "rich                    13.9.4\n",
      "scipy                   1.15.0\n",
      "setuptools              75.6.0\n",
      "six                     1.16.0\n",
      "stack-data              0.6.3\n",
      "tensorboard             2.18.0\n",
      "tensorboard-data-server 0.7.2\n",
      "tensorflow              2.18.0\n",
      "termcolor               2.5.0\n",
      "tornado                 6.4.2\n",
      "traitlets               5.14.3\n",
      "typing_extensions       4.12.2\n",
      "urllib3                 2.2.3\n",
      "wcwidth                 0.2.13\n",
      "Werkzeug                3.1.3\n",
      "wheel                   0.45.0\n",
      "wrapt                   1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. Single Image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "\n",
    "# Create data generator\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = load_img('Dataset/New/Original/NailMelanoma/NailMelanoma (1).jpg')\n",
    "x = img_to_array(img)\n",
    "x = tf.expand_dims(x, 0)  # Add batch dimension\n",
    "\n",
    "# Generate and save augmented images\n",
    "i = 0\n",
    "for batch in datagen.flow(\n",
    "    x, \n",
    "    batch_size=1,\n",
    "    save_to_dir='Dataset/New/Augmented/NailMelanoma',\n",
    "    save_prefix='NailMelanoma',\n",
    "    save_format='jpg'\n",
    "):\n",
    "    i += 1\n",
    "    if i >= 20:\n",
    "        break  # Stop after generating 20 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Batch Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images to process\n",
      "Processed image 1/100: Healthy (92).jpg\n",
      "Processed image 2/100: Healthy (75).jpg\n",
      "Processed image 3/100: Healthy (18).jpg\n",
      "Processed image 4/100: Healthy (68).jpg\n",
      "Processed image 5/100: Healthy (51).jpg\n",
      "Processed image 6/100: Healthy (87).jpg\n",
      "Processed image 7/100: Healthy (94).jpg\n",
      "Processed image 8/100: Healthy (31).jpg\n",
      "Processed image 9/100: Healthy (64).jpg\n",
      "Processed image 10/100: Healthy (48).jpg\n",
      "Processed image 11/100: Healthy (15).jpg\n",
      "Processed image 12/100: Healthy (42).jpg\n",
      "Processed image 13/100: Healthy (2).jpg\n",
      "Processed image 14/100: Healthy (43).jpg\n",
      "Processed image 15/100: Healthy (99).jpg\n",
      "Processed image 16/100: Healthy (91).jpg\n",
      "Processed image 17/100: Healthy (61).jpg\n",
      "Processed image 18/100: Healthy (12).jpg\n",
      "Processed image 19/100: Healthy (71).jpg\n",
      "Processed image 20/100: Healthy (65).jpg\n",
      "Processed image 21/100: Healthy (53).jpg\n",
      "Processed image 22/100: Healthy (67).jpg\n",
      "Processed image 23/100: Healthy (32).jpg\n",
      "Processed image 24/100: Healthy (60).jpg\n",
      "Processed image 25/100: Healthy (88).jpg\n",
      "Processed image 26/100: Healthy (7).jpg\n",
      "Processed image 27/100: Healthy (20).jpg\n",
      "Processed image 28/100: Healthy (38).jpg\n",
      "Processed image 29/100: Healthy (97).jpg\n",
      "Processed image 30/100: Healthy (21).jpg\n",
      "Processed image 31/100: Healthy (22).jpg\n",
      "Processed image 32/100: Healthy (16).jpg\n",
      "Processed image 33/100: Healthy (8).jpg\n",
      "Processed image 34/100: Healthy (11).jpg\n",
      "Processed image 35/100: Healthy (100).jpg\n",
      "Processed image 36/100: Healthy (19).jpg\n",
      "Processed image 37/100: Healthy (37).jpg\n",
      "Processed image 38/100: Healthy (13).jpg\n",
      "Processed image 39/100: Healthy (56).jpg\n",
      "Processed image 40/100: Healthy (28).jpg\n",
      "Processed image 41/100: Healthy (77).jpg\n",
      "Processed image 42/100: Healthy (84).jpg\n",
      "Processed image 43/100: Healthy (45).jpg\n",
      "Processed image 44/100: Healthy (6).jpg\n",
      "Processed image 45/100: Healthy (29).jpg\n",
      "Processed image 46/100: Healthy (96).jpg\n",
      "Processed image 47/100: Healthy (85).jpg\n",
      "Processed image 48/100: Healthy (33).jpg\n",
      "Processed image 49/100: Healthy (49).jpg\n",
      "Processed image 50/100: Healthy (44).jpg\n",
      "Processed image 51/100: Healthy (70).jpg\n",
      "Processed image 52/100: Healthy (3).jpg\n",
      "Processed image 53/100: Healthy (34).jpg\n",
      "Processed image 54/100: Healthy (35).jpg\n",
      "Processed image 55/100: Healthy (80).jpg\n",
      "Processed image 56/100: Healthy (83).jpg\n",
      "Processed image 57/100: Healthy (41).jpg\n",
      "Processed image 58/100: Healthy (72).jpg\n",
      "Processed image 59/100: Healthy (95).jpg\n",
      "Processed image 60/100: Healthy (30).jpg\n",
      "Processed image 61/100: Healthy (93).jpg\n",
      "Processed image 62/100: Healthy (39).jpg\n",
      "Processed image 63/100: Healthy (10).jpg\n",
      "Processed image 64/100: Healthy (62).jpg\n",
      "Processed image 65/100: Healthy (26).jpg\n",
      "Processed image 66/100: Healthy (24).jpg\n",
      "Processed image 67/100: Healthy (78).jpg\n",
      "Processed image 68/100: Healthy (14).jpg\n",
      "Processed image 69/100: Healthy (23).jpg\n",
      "Processed image 70/100: Healthy (66).jpg\n",
      "Processed image 71/100: Healthy (36).jpg\n",
      "Processed image 72/100: Healthy (73).jpg\n",
      "Processed image 73/100: Healthy (82).jpg\n",
      "Processed image 74/100: Healthy (27).jpg\n",
      "Processed image 75/100: Healthy (25).jpg\n",
      "Processed image 76/100: Healthy (54).jpg\n",
      "Processed image 77/100: Healthy (81).jpg\n",
      "Processed image 78/100: Healthy (5).jpg\n",
      "Processed image 79/100: Healthy (74).jpg\n",
      "Processed image 80/100: Healthy (89).jpg\n",
      "Processed image 81/100: Healthy (57).jpg\n",
      "Processed image 82/100: Healthy (63).jpg\n",
      "Processed image 83/100: Healthy (1).jpg\n",
      "Processed image 84/100: Healthy (59).jpg\n",
      "Processed image 85/100: Healthy (50).jpg\n",
      "Processed image 86/100: Healthy (55).jpg\n",
      "Processed image 87/100: Healthy (86).jpg\n",
      "Processed image 88/100: Healthy (58).jpg\n",
      "Processed image 89/100: Healthy (46).jpg\n",
      "Processed image 90/100: Healthy (98).jpg\n",
      "Processed image 91/100: Healthy (9).jpg\n",
      "Processed image 92/100: Healthy (90).jpg\n",
      "Processed image 93/100: Healthy (40).jpg\n",
      "Processed image 94/100: Healthy (52).jpg\n",
      "Processed image 95/100: Healthy (69).jpg\n",
      "Processed image 96/100: Healthy (76).jpg\n",
      "Processed image 97/100: Healthy (79).jpg\n",
      "Processed image 98/100: Healthy (17).jpg\n",
      "Processed image 99/100: Healthy (4).jpg\n",
      "Processed image 100/100: Healthy (47).jpg\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def augment_images(\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    augmentations_per_image=20,\n",
    "    seed=42,\n",
    "):\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create data generator\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Get list of all images in input directory\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    image_files = [\n",
    "        f for f in os.listdir(input_dir) \n",
    "        if os.path.splitext(f.lower())[1] in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, image_file in enumerate(image_files, 1):\n",
    "        try:\n",
    "            # Load and preprocess the image\n",
    "            input_path = os.path.join(input_dir, image_file)\n",
    "            img = load_img(input_path)\n",
    "            x = img_to_array(img)\n",
    "            x = tf.expand_dims(x, 0)\n",
    "            \n",
    "            # Generate and save augmented versions\n",
    "            i = 0\n",
    "            base_filename = os.path.splitext(image_file)[0]\n",
    "            \n",
    "            for batch in datagen.flow(\n",
    "                x,\n",
    "                batch_size=1,\n",
    "                save_to_dir=output_dir,\n",
    "                save_prefix=f\"{base_filename}\",\n",
    "                save_format='jpg'\n",
    "            ):\n",
    "                i += 1\n",
    "                if i >= augmentations_per_image:\n",
    "                    break\n",
    "            \n",
    "            print(f\"Processed image {idx}/{len(image_files)}: {image_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Augment NailMelanoma Dataset\n",
    "input_directory = 'Dataset/New/Original/NailMelanoma'\n",
    "output_directory = 'Dataset/New/Augmented/NailMelanoma'\n",
    "\n",
    "augment_images(\n",
    "    input_dir=input_directory,\n",
    "    output_dir=output_directory,\n",
    "    augmentations_per_image=20,  # Number of augmented versions per image\n",
    ")\n",
    "\n",
    "# Augment Healthy Dataset\n",
    "input_directory = 'Dataset/New/Original/Healthy'\n",
    "output_directory = 'Dataset/New/Augmented/Healthy'\n",
    "\n",
    "augment_images(\n",
    "    input_dir=input_directory,\n",
    "    output_dir=output_directory,\n",
    "    augmentations_per_image=20,  # Number of augmented versions per image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images to process\n",
      "Expected output: 2000 augmented images\n",
      "Processed image 1/100: Healthy (92).jpg - Generated 20 augmentations\n",
      "Processed image 2/100: Healthy (75).jpg - Generated 20 augmentations\n",
      "Processed image 3/100: Healthy (18).jpg - Generated 20 augmentations\n",
      "Processed image 4/100: Healthy (68).jpg - Generated 20 augmentations\n",
      "Processed image 5/100: Healthy (51).jpg - Generated 20 augmentations\n",
      "Processed image 6/100: Healthy (87).jpg - Generated 20 augmentations\n",
      "Processed image 7/100: Healthy (94).jpg - Generated 20 augmentations\n",
      "Processed image 8/100: Healthy (31).jpg - Generated 20 augmentations\n",
      "Processed image 9/100: Healthy (64).jpg - Generated 20 augmentations\n",
      "Processed image 10/100: Healthy (48).jpg - Generated 20 augmentations\n",
      "Processed image 11/100: Healthy (15).jpg - Generated 20 augmentations\n",
      "Processed image 12/100: Healthy (42).jpg - Generated 20 augmentations\n",
      "Processed image 13/100: Healthy (2).jpg - Generated 20 augmentations\n",
      "Processed image 14/100: Healthy (43).jpg - Generated 20 augmentations\n",
      "Processed image 15/100: Healthy (99).jpg - Generated 20 augmentations\n",
      "Processed image 16/100: Healthy (91).jpg - Generated 20 augmentations\n",
      "Processed image 17/100: Healthy (61).jpg - Generated 20 augmentations\n",
      "Processed image 18/100: Healthy (12).jpg - Generated 20 augmentations\n",
      "Processed image 19/100: Healthy (71).jpg - Generated 20 augmentations\n",
      "Processed image 20/100: Healthy (65).jpg - Generated 20 augmentations\n",
      "Processed image 21/100: Healthy (53).jpg - Generated 20 augmentations\n",
      "Processed image 22/100: Healthy (67).jpg - Generated 20 augmentations\n",
      "Processed image 23/100: Healthy (32).jpg - Generated 20 augmentations\n",
      "Processed image 24/100: Healthy (60).jpg - Generated 20 augmentations\n",
      "Processed image 25/100: Healthy (88).jpg - Generated 20 augmentations\n",
      "Processed image 26/100: Healthy (7).jpg - Generated 20 augmentations\n",
      "Processed image 27/100: Healthy (20).jpg - Generated 20 augmentations\n",
      "Processed image 28/100: Healthy (38).jpg - Generated 20 augmentations\n",
      "Processed image 29/100: Healthy (97).jpg - Generated 20 augmentations\n",
      "Processed image 30/100: Healthy (21).jpg - Generated 20 augmentations\n",
      "Processed image 31/100: Healthy (22).jpg - Generated 20 augmentations\n",
      "Processed image 32/100: Healthy (16).jpg - Generated 20 augmentations\n",
      "Processed image 33/100: Healthy (8).jpg - Generated 20 augmentations\n",
      "Processed image 34/100: Healthy (11).jpg - Generated 20 augmentations\n",
      "Processed image 35/100: Healthy (100).jpg - Generated 20 augmentations\n",
      "Processed image 36/100: Healthy (19).jpg - Generated 20 augmentations\n",
      "Processed image 37/100: Healthy (37).jpg - Generated 20 augmentations\n",
      "Processed image 38/100: Healthy (13).jpg - Generated 20 augmentations\n",
      "Processed image 39/100: Healthy (56).jpg - Generated 20 augmentations\n",
      "Processed image 40/100: Healthy (28).jpg - Generated 20 augmentations\n",
      "Processed image 41/100: Healthy (77).jpg - Generated 20 augmentations\n",
      "Processed image 42/100: Healthy (84).jpg - Generated 20 augmentations\n",
      "Processed image 43/100: Healthy (45).jpg - Generated 20 augmentations\n",
      "Processed image 44/100: Healthy (6).jpg - Generated 20 augmentations\n",
      "Processed image 45/100: Healthy (29).jpg - Generated 20 augmentations\n",
      "Processed image 46/100: Healthy (96).jpg - Generated 20 augmentations\n",
      "Processed image 47/100: Healthy (85).jpg - Generated 20 augmentations\n",
      "Processed image 48/100: Healthy (33).jpg - Generated 20 augmentations\n",
      "Processed image 49/100: Healthy (49).jpg - Generated 20 augmentations\n",
      "Processed image 50/100: Healthy (44).jpg - Generated 20 augmentations\n",
      "Processed image 51/100: Healthy (70).jpg - Generated 20 augmentations\n",
      "Processed image 52/100: Healthy (3).jpg - Generated 20 augmentations\n",
      "Processed image 53/100: Healthy (34).jpg - Generated 20 augmentations\n",
      "Processed image 54/100: Healthy (35).jpg - Generated 20 augmentations\n",
      "Processed image 55/100: Healthy (80).jpg - Generated 20 augmentations\n",
      "Processed image 56/100: Healthy (83).jpg - Generated 20 augmentations\n",
      "Processed image 57/100: Healthy (41).jpg - Generated 20 augmentations\n",
      "Processed image 58/100: Healthy (72).jpg - Generated 20 augmentations\n",
      "Processed image 59/100: Healthy (95).jpg - Generated 20 augmentations\n",
      "Processed image 60/100: Healthy (30).jpg - Generated 20 augmentations\n",
      "Processed image 61/100: Healthy (93).jpg - Generated 20 augmentations\n",
      "Processed image 62/100: Healthy (39).jpg - Generated 20 augmentations\n",
      "Processed image 63/100: Healthy (10).jpg - Generated 20 augmentations\n",
      "Processed image 64/100: Healthy (62).jpg - Generated 20 augmentations\n",
      "Processed image 65/100: Healthy (26).jpg - Generated 20 augmentations\n",
      "Processed image 66/100: Healthy (24).jpg - Generated 20 augmentations\n",
      "Processed image 67/100: Healthy (78).jpg - Generated 20 augmentations\n",
      "Processed image 68/100: Healthy (14).jpg - Generated 20 augmentations\n",
      "Processed image 69/100: Healthy (23).jpg - Generated 20 augmentations\n",
      "Processed image 70/100: Healthy (66).jpg - Generated 20 augmentations\n",
      "Processed image 71/100: Healthy (36).jpg - Generated 20 augmentations\n",
      "Processed image 72/100: Healthy (73).jpg - Generated 20 augmentations\n",
      "Processed image 73/100: Healthy (82).jpg - Generated 20 augmentations\n",
      "Processed image 74/100: Healthy (27).jpg - Generated 20 augmentations\n",
      "Processed image 75/100: Healthy (25).jpg - Generated 20 augmentations\n",
      "Processed image 76/100: Healthy (54).jpg - Generated 20 augmentations\n",
      "Processed image 77/100: Healthy (81).jpg - Generated 20 augmentations\n",
      "Processed image 78/100: Healthy (5).jpg - Generated 20 augmentations\n",
      "Processed image 79/100: Healthy (74).jpg - Generated 20 augmentations\n",
      "Processed image 80/100: Healthy (89).jpg - Generated 20 augmentations\n",
      "Processed image 81/100: Healthy (57).jpg - Generated 20 augmentations\n",
      "Processed image 82/100: Healthy (63).jpg - Generated 20 augmentations\n",
      "Processed image 83/100: Healthy (1).jpg - Generated 20 augmentations\n",
      "Processed image 84/100: Healthy (59).jpg - Generated 20 augmentations\n",
      "Processed image 85/100: Healthy (50).jpg - Generated 20 augmentations\n",
      "Processed image 86/100: Healthy (55).jpg - Generated 20 augmentations\n",
      "Processed image 87/100: Healthy (86).jpg - Generated 20 augmentations\n",
      "Processed image 88/100: Healthy (58).jpg - Generated 20 augmentations\n",
      "Processed image 89/100: Healthy (46).jpg - Generated 20 augmentations\n",
      "Processed image 90/100: Healthy (98).jpg - Generated 20 augmentations\n",
      "Processed image 91/100: Healthy (9).jpg - Generated 20 augmentations\n",
      "Processed image 92/100: Healthy (90).jpg - Generated 20 augmentations\n",
      "Processed image 93/100: Healthy (40).jpg - Generated 20 augmentations\n",
      "Processed image 94/100: Healthy (52).jpg - Generated 20 augmentations\n",
      "Processed image 95/100: Healthy (69).jpg - Generated 20 augmentations\n",
      "Processed image 96/100: Healthy (76).jpg - Generated 20 augmentations\n",
      "Processed image 97/100: Healthy (79).jpg - Generated 20 augmentations\n",
      "Processed image 98/100: Healthy (17).jpg - Generated 20 augmentations\n",
      "Processed image 99/100: Healthy (4).jpg - Generated 20 augmentations\n",
      "Processed image 100/100: Healthy (47).jpg - Generated 20 augmentations\n",
      "\n",
      "Processing complete!\n",
      "Total augmented images generated: 2000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def augment_images(\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    augmentations_per_image=20,\n",
    "    seed=42  # Added seed for reproducibility\n",
    "):\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create data generator with fixed seed\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Get list of all images in input directory\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png'}\n",
    "    image_files = [\n",
    "        f for f in os.listdir(input_dir) \n",
    "        if os.path.splitext(f.lower())[1] in valid_extensions\n",
    "    ]\n",
    "    \n",
    "    total_images = len(image_files)\n",
    "    print(f\"Found {total_images} images to process\")\n",
    "    expected_total = total_images * augmentations_per_image\n",
    "    print(f\"Expected output: {expected_total} augmented images\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, image_file in enumerate(image_files, 1):\n",
    "        try:\n",
    "            # Load and preprocess the image\n",
    "            input_path = os.path.join(input_dir, image_file)\n",
    "            img = load_img(input_path)\n",
    "            x = img_to_array(img)\n",
    "            x = tf.expand_dims(x, 0)\n",
    "            \n",
    "            base_filename = os.path.splitext(image_file)[0]\n",
    "            current_count = 0\n",
    "            \n",
    "            # Set a specific seed for each image to ensure reproducibility\n",
    "            image_seed = seed + idx\n",
    "            np.random.seed(image_seed)\n",
    "            tf.random.set_seed(image_seed)\n",
    "            \n",
    "            # Generate augmented images one at a time\n",
    "            while current_count < augmentations_per_image:\n",
    "                # Generate the augmented image\n",
    "                aug_img = next(datagen.flow(\n",
    "                    x,\n",
    "                    batch_size=1,\n",
    "                    seed=image_seed + current_count\n",
    "                ))\n",
    "                \n",
    "                # Save the augmented image with a guaranteed unique filename\n",
    "                output_filename = f\"{base_filename}_{current_count+1:03d}.jpg\"\n",
    "                output_path = os.path.join(output_dir, output_filename)\n",
    "                tf.keras.preprocessing.image.save_img(output_path, aug_img[0])\n",
    "                \n",
    "                current_count += 1\n",
    "                processed_count += 1\n",
    "            \n",
    "            print(f\"Processed image {idx}/{total_images}: {image_file} - Generated {current_count} augmentations\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total augmented images generated: {processed_count}\")\n",
    "    assert processed_count == expected_total, f\"Expected {expected_total} images but generated {processed_count}\"\n",
    "\n",
    "# Augment NailMelanoma\n",
    "input_directory = 'Dataset/New/Original/NailMelanoma'\n",
    "output_directory = 'Dataset/New/Augmented/NailMelanoma'\n",
    "\n",
    "augment_images(\n",
    "    input_dir=input_directory,\n",
    "    output_dir=output_directory,\n",
    "    augmentations_per_image=20,\n",
    "    seed=42  # Add seed for reproducibility\n",
    ")\n",
    "\n",
    "# Augment Healthy\n",
    "input_directory = 'Dataset/New/Original/Healthy'\n",
    "output_directory = 'Dataset/New/Augmented/Healthy'\n",
    "\n",
    "augment_images(\n",
    "    input_dir=input_directory,\n",
    "    output_dir=output_directory,\n",
    "    augmentations_per_image=20,\n",
    "    seed=42  # Add seed for reproducibility\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
